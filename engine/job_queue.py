import json
import logging
import os
import re
import shutil
import sqlite3
import subprocess
import tempfile
import threading
import time
import urllib.parse
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from uuid import uuid4

import requests
from yt_dlp import YoutubeDL
from yt_dlp.utils import DownloadError, ExtractorError

from engine.paths import EnginePaths, TOKENS_DIR, resolve_dir
from metadata.queue import enqueue_metadata

JOB_STATUS_QUEUED = "queued"
JOB_STATUS_RUNNING = "running"
JOB_STATUS_COMPLETED = "completed"
JOB_STATUS_FAILED = "failed"
JOB_STATUS_CANCELED = "canceled"

TERMINAL_STATUSES = {JOB_STATUS_COMPLETED, JOB_STATUS_FAILED, JOB_STATUS_CANCELED}

_FORMAT_VIDEO = (
    "bestvideo[ext=webm][height<=1080]+bestaudio[ext=webm]/"
    "bestvideo[ext=webm][height<=720]+bestaudio[ext=webm]/"
    "bestvideo[ext=mp4][height<=1080]+bestaudio[ext=m4a]/"
    "bestvideo[ext=mp4][height<=720]+bestaudio[ext=m4a]/"
    "bestvideo*+bestaudio/best"
)
_FORMAT_AUDIO = "bestaudio/best"

_AUDIO_FORMATS = {"mp3", "m4a", "flac"}

_AUDIO_TITLE_CLEAN_RE = re.compile(
    r"\s*[\(\[\{][^)\]\}]*?(official|music video|video|lyric|audio|visualizer|full video|hd|4k)[^)\]\}]*?[\)\]\}]\s*",
    re.IGNORECASE,
)
_AUDIO_TITLE_TRAIL_RE = re.compile(
    r"\s*-\s*(official|music video|video|lyric|audio|visualizer|full video).*$",
    re.IGNORECASE,
)
_AUDIO_ARTIST_VEVO_RE = re.compile(r"(vevo)$", re.IGNORECASE)

_YTDLP_DOWNLOAD_UNSAFE_KEYS = {"download", "skip_download", "simulate", "extract_flat"}

_YTDLP_DOWNLOAD_ALLOWLIST = {
    "concurrent_fragment_downloads",
    "cookiefile",
    "cookiesfrombrowser",
    "forceipv4",
    "forceipv6",
    "fragment_retries",
    "geo_verification_proxy",
    "http_headers",
    "max_sleep_interval",
    "nocheckcertificate",
    "noproxy",
    "proxy",
    "ratelimit",
    "retries",
    "sleep_interval",
    "socket_timeout",
    "source_address",
    "throttledratelimit",
    "user_agent",
}


@dataclass(frozen=True)
class DownloadJob:
    id: str
    origin: str
    origin_id: str
    media_type: str
    media_intent: str
    source: str
    url: str
    status: str
    queued: str | None
    running: str | None
    completed: str | None
    failed: str | None
    canceled: str | None
    attempts: int
    max_attempts: int
    created_at: str | None
    updated_at: str | None
    last_error: str | None
    trace_id: str
    output_template: dict | None


def utc_now():
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat()


def _log_event(level, message, **fields):
    payload = {"message": message, **fields}
    logging.log(level, json.dumps(payload, sort_keys=True))


def ensure_download_jobs_table(conn):
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS download_jobs (
            id TEXT PRIMARY KEY,
            origin TEXT NOT NULL,
            origin_id TEXT NOT NULL,
            media_type TEXT NOT NULL,
            media_intent TEXT NOT NULL,
            source TEXT NOT NULL,
            url TEXT NOT NULL,
            status TEXT NOT NULL,
            queued TEXT,
            running TEXT,
            completed TEXT,
            failed TEXT,
            canceled TEXT,
            attempts INTEGER NOT NULL,
            max_attempts INTEGER NOT NULL DEFAULT 3,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            last_error TEXT,
            trace_id TEXT NOT NULL UNIQUE,
            output_template TEXT
        )
        """
    )
    cur.execute("CREATE INDEX IF NOT EXISTS idx_download_jobs_status ON download_jobs (status)")
    cur.execute(
        "CREATE INDEX IF NOT EXISTS idx_download_jobs_source_status ON download_jobs (source, status)"
    )
    cur.execute("CREATE INDEX IF NOT EXISTS idx_download_jobs_created ON download_jobs (created_at)")
    conn.commit()


def is_music_media_type(value):
    if value is None:
        return False
    value = str(value).strip().lower()
    return value in {"music", "audio"}



class DownloadJobStore:
    def __init__(self, db_path):
        self.db_path = db_path

    def _connect(self):
        conn = sqlite3.connect(self.db_path, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        return conn

    def _row_to_job(self, row):
        if not row:
            return None
        output_template = row["output_template"]
        parsed_output = None
        if output_template:
            try:
                parsed_output = json.loads(output_template)
            except json.JSONDecodeError:
                parsed_output = None
        return DownloadJob(
            id=row["id"],
            origin=row["origin"],
            origin_id=row["origin_id"],
            media_type=row["media_type"],
            media_intent=row["media_intent"],
            source=row["source"],
            url=row["url"],
            status=row["status"],
            queued=row["queued"],
            running=row["running"],
            completed=row["completed"],
            failed=row["failed"],
            canceled=row["canceled"],
            attempts=row["attempts"],
            max_attempts=row["max_attempts"],
            created_at=row["created_at"],
            updated_at=row["updated_at"],
            last_error=row["last_error"],
            trace_id=row["trace_id"],
            output_template=parsed_output,
        )

    def list_sources_with_queued_jobs(self, *, now=None):
        now = now or utc_now()
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                "SELECT DISTINCT source FROM download_jobs WHERE status=? AND (queued IS NULL OR queued<=?)",
                (JOB_STATUS_QUEUED, now),
            )
            return [row[0] for row in cur.fetchall()]
        finally:
            conn.close()

    def job_exists(self, origin, origin_id, url):
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                "SELECT 1 FROM download_jobs WHERE origin=? AND origin_id=? AND url=? LIMIT 1",
                (origin, origin_id, url),
            )
            return cur.fetchone() is not None
        finally:
            conn.close()

    def find_active_job(self, origin, origin_id, url):
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                """
                SELECT * FROM download_jobs
                WHERE origin=? AND origin_id=? AND url=? AND status NOT IN (?, ?, ?)
                ORDER BY created_at DESC
                LIMIT 1
                """,
                (origin, origin_id, url, JOB_STATUS_COMPLETED, JOB_STATUS_FAILED, JOB_STATUS_CANCELED),
            )
            row = cur.fetchone()
            if not row:
                return None
            return self._row_to_job(row)
        finally:
            conn.close()

    def enqueue_job(
        self,
        *,
        origin,
        origin_id,
        media_type,
        media_intent,
        source,
        url,
        output_template=None,
        max_attempts=3,
        trace_id=None,
    ):
        origin_id = origin_id or ""
        existing = self.find_active_job(origin, origin_id, url)
        if existing:
            return existing.id, False

        job_id = uuid4().hex
        now = utc_now()
        trace_id = trace_id or uuid4().hex
        output_template_json = json.dumps(output_template) if output_template else None

        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                """
                INSERT INTO download_jobs (
                    id, origin, origin_id, media_type, media_intent, source, url,
                    status, queued, running, completed, failed, canceled, attempts,
                    max_attempts, created_at, updated_at, last_error, trace_id, output_template
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    job_id,
                    origin,
                    origin_id,
                    media_type,
                    media_intent,
                    source,
                    url,
                    JOB_STATUS_QUEUED,
                    now,
                    None,
                    None,
                    None,
                    None,
                    0,
                    max_attempts,
                    now,
                    now,
                    None,
                    trace_id,
                    output_template_json,
                ),
            )
            conn.commit()
            return job_id, True
        finally:
            conn.close()

    def claim_next_job(self, source, *, now=None):
        now = now or utc_now()
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute("BEGIN IMMEDIATE")
            cur.execute(
                "SELECT 1 FROM download_jobs WHERE status=? AND source=? LIMIT 1",
                (JOB_STATUS_RUNNING, source),
            )
            if cur.fetchone():
                conn.commit()
                return None
            cur.execute(
                """
                SELECT * FROM download_jobs
                WHERE status=? AND source=? AND (queued IS NULL OR queued<=?)
                ORDER BY created_at ASC
                LIMIT 1
                """,
                (JOB_STATUS_QUEUED, source, now),
            )
            row = cur.fetchone()
            if not row:
                conn.commit()
                return None
            job_id = row["id"]
            cur.execute(
                """
                UPDATE download_jobs
                SET status=?, running=?, updated_at=?
                WHERE id=? AND status=?
                """,
                (JOB_STATUS_RUNNING, now, now, job_id, JOB_STATUS_QUEUED),
            )
            if cur.rowcount != 1:
                conn.commit()
                return None
            conn.commit()
            updated_row = dict(row)
            updated_row["status"] = JOB_STATUS_RUNNING
            updated_row["running"] = now
            updated_row["updated_at"] = now
            return self._row_to_job(updated_row)
        finally:
            conn.close()
    def mark_completed(self, job_id):
        now = utc_now()
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                """
                UPDATE download_jobs
                SET status=?, completed=?, updated_at=?
                WHERE id=?
                """,
                (JOB_STATUS_COMPLETED, now, now, job_id),
            )
            conn.commit()
        finally:
            conn.close()

    def mark_canceled(self, job_id, *, reason=None):
        now = utc_now()
        conn = self._connect()
        try:
            cur = conn.cursor()
            cur.execute(
                """
                UPDATE download_jobs
                SET status=?, canceled=?, updated_at=?, last_error=?
                WHERE id=?
                """,
                (JOB_STATUS_CANCELED, now, now, reason, job_id),
            )
            conn.commit()
        finally:
            conn.close()

    def record_failure(self, job, *, error_message, retryable, retry_delay_seconds):
        attempts = job.attempts + 1
        now = utc_now()
        conn = self._connect()
        try:
            cur = conn.cursor()
            if retryable and attempts < job.max_attempts:
                next_ready = (datetime.now(timezone.utc) + timedelta(seconds=retry_delay_seconds))
                queued_at = next_ready.replace(microsecond=0).isoformat()
                cur.execute(
                    """
                    UPDATE download_jobs
                    SET status=?, queued=?, updated_at=?, attempts=?, last_error=?
                    WHERE id=?
                    """,
                    (JOB_STATUS_QUEUED, queued_at, now, attempts, error_message, job.id),
                )
                conn.commit()
                return JOB_STATUS_QUEUED

            cur.execute(
                """
                UPDATE download_jobs
                SET status=?, failed=?, updated_at=?, attempts=?, last_error=?
                WHERE id=?
                """,
                (JOB_STATUS_FAILED, now, now, attempts, error_message, job.id),
            )
            conn.commit()
            return JOB_STATUS_FAILED
        finally:
            conn.close()


class DownloadWorkerEngine:
    def __init__(
        self,
        db_path,
        config,
        paths: EnginePaths,
        *,
        retry_delay_seconds=30,
        adapters=None,
    ):
        self.db_path = db_path
        self.config = config or {}
        self.paths = paths
        self.retry_delay_seconds = retry_delay_seconds
        self.store = DownloadJobStore(db_path)
        self.adapters = adapters or default_adapters()
        self._locks = {}
        self._locks_lock = threading.Lock()

    def run_once(self, *, stop_event=None):
        sources = self.store.list_sources_with_queued_jobs()
        threads = []
        for source in sources:
            if stop_event and stop_event.is_set():
                break
            lock = self._get_source_lock(source)
            if not lock.acquire(blocking=False):
                continue
            thread = threading.Thread(
                target=self._run_source_once,
                args=(source, lock, stop_event),
                daemon=False,
            )
            thread.start()
            threads.append(thread)
        for thread in threads:
            thread.join()

    def run_loop(self, *, poll_seconds=5, stop_event=None):
        _log_event(logging.INFO, "worker_started")
        _log_event(logging.INFO, "queue_polling_started")
        while True:
            if stop_event and stop_event.is_set():
                return
            self.run_once(stop_event=stop_event)
            time.sleep(poll_seconds)

    def _get_source_lock(self, source):
        with self._locks_lock:
            lock = self._locks.get(source)
            if not lock:
                lock = threading.Lock()
                self._locks[source] = lock
            return lock

    def _run_source_once(self, source, lock, stop_event):
        try:
            if stop_event and stop_event.is_set():
                return
            job = self.store.claim_next_job(source)
            if not job:
                return
            _log_event(
                logging.INFO,
                "job_claimed",
                job_id=job.id,
                trace_id=job.trace_id,
                source=job.source,
                origin=job.origin,
                media_intent=job.media_intent,
            )
            self._execute_job(job, stop_event=stop_event)
        finally:
            lock.release()

    def _execute_job(self, job, *, stop_event=None):
        if job.status != JOB_STATUS_RUNNING:
            _log_event(
                logging.ERROR,
                "job_not_running",
                job_id=job.id,
                trace_id=job.trace_id,
                source=job.source,
                origin=job.origin,
                media_intent=job.media_intent,
            )
            return
        adapter = self.adapters.get(job.source)
        if not adapter:
            _log_event(
                logging.ERROR,
                "adapter_missing",
                job_id=job.id,
                trace_id=job.trace_id,
                source=job.source,
            )
            self.store.record_failure(
                job,
                error_message=f"adapter_missing:{job.source}",
                retryable=False,
                retry_delay_seconds=self.retry_delay_seconds,
            )
            return
        _log_event(
            logging.INFO,
            "job_started",
            job_id=job.id,
            trace_id=job.trace_id,
            source=job.source,
            origin=job.origin,
            media_intent=job.media_intent,
        )
        try:
            result = adapter.execute(job, self.config, self.paths, stop_event=stop_event)
            if not result:
                raise RuntimeError("adapter_execute_failed")
            final_path, meta = result
            record_download_history(
                self.db_path,
                job,
                final_path,
                meta=meta,
            )
            self.store.mark_completed(job.id)
            _log_event(
                logging.INFO,
                "job_completed",
                job_id=job.id,
                trace_id=job.trace_id,
                source=job.source,
                origin=job.origin,
                media_intent=job.media_intent,
                path=final_path,
            )
        except Exception as exc:
            error_message = f"{type(exc).__name__}: {exc}"
            retryable = is_retryable_error(exc)
            new_status = self.store.record_failure(
                job,
                error_message=error_message,
                retryable=retryable,
                retry_delay_seconds=self.retry_delay_seconds,
            )
            _log_event(
                logging.ERROR,
                "job_failed",
                job_id=job.id,
                trace_id=job.trace_id,
                source=job.source,
                origin=job.origin,
                media_intent=job.media_intent,
                retryable=retryable,
                status=new_status,
                error=error_message,
            )


class YouTubeAdapter:
    def execute(self, job, config, paths, *, stop_event=None):
        output_template = job.output_template or {}
        output_dir = output_template.get("output_dir") or paths.single_downloads_dir
        audio_mode = is_music_media_type(job.media_type)
        final_format = output_template.get("final_format")
        if isinstance(final_format, str):
            final_format = final_format.strip().lower()
        if audio_mode:
            if not final_format or final_format not in _AUDIO_FORMATS:
                if final_format:
                    logging.warning("Unsupported audio format %s; defaulting to mp3", final_format)
                final_format = "mp3"
        filename_template = output_template.get("filename_template")
        audio_template = output_template.get("audio_filename_template")

        resolved_dir = resolve_dir(output_dir, paths.single_downloads_dir)
        temp_dir = os.path.join(paths.temp_downloads_dir, job.id)
        os.makedirs(temp_dir, exist_ok=True)

        try:
            cookie_file = resolve_cookie_file(config)
            info, local_file = download_with_ytdlp(
                job.url,
                temp_dir,
                config,
                audio_mode=audio_mode,
                final_format=final_format,
                cookie_file=cookie_file,
                stop_event=stop_event,
            )
            if not info or not local_file:
                shutil.rmtree(temp_dir, ignore_errors=True)
                return None

            meta = extract_meta(info, fallback_url=job.url)
            video_id = meta.get("video_id") or job.id
            ext = os.path.splitext(local_file)[1].lstrip(".")
            if audio_mode:
                ext = final_format or "mp3"
            elif not ext:
                ext = final_format or "webm"
            template = audio_template if audio_mode else filename_template
            cleaned_name = build_output_filename(meta, video_id, ext, template, audio_mode)

            if stop_event and stop_event.is_set():
                shutil.rmtree(temp_dir, ignore_errors=True)
                return None

            if not audio_mode:
                embed_metadata(local_file, meta, video_id, paths.thumbs_dir)

            final_path = os.path.join(resolved_dir, cleaned_name)
            os.makedirs(os.path.dirname(final_path), exist_ok=True)
            atomic_move(local_file, final_path)
            shutil.rmtree(temp_dir, ignore_errors=True)

            if audio_mode:
                enqueue_media_metadata(final_path, meta, config)

            return final_path, meta
        except Exception:
            shutil.rmtree(temp_dir, ignore_errors=True)
            raise


def default_adapters():
    adapter = YouTubeAdapter()
    return {
        "youtube": adapter,
        "youtube_music": adapter,
        "soundcloud": adapter,
        "bandcamp": adapter,
    }


def resolve_cookie_file(config):
    cookie_value = (config or {}).get("yt_dlp_cookies")
    if not cookie_value:
        return None
    try:
        resolved = resolve_dir(cookie_value, TOKENS_DIR)
    except ValueError as exc:
        logging.error("Invalid yt-dlp cookies path: %s", exc)
        return None
    if not os.path.exists(resolved):
        logging.warning("yt-dlp cookies file not found: %s", resolved)
        return None
    return resolved


def resolve_media_type(config, *, playlist_entry=None, url=None):
    media_type = None
    if isinstance(playlist_entry, dict):
        media_type = playlist_entry.get("media_type") or playlist_entry.get("media")
    if not media_type and isinstance(config, dict):
        media_type = config.get("media_type")
    if media_type:
        media_type = str(media_type).strip().lower()
        if media_type in {"music", "audio"}:
            return "music"
        if media_type == "video":
            return "video"

    legacy_audio = None
    if isinstance(playlist_entry, dict):
        legacy_audio = playlist_entry.get("audio_only")
        if legacy_audio is None:
            legacy_audio = playlist_entry.get("music_mode")
    if legacy_audio is None and isinstance(config, dict):
        legacy_audio = config.get("audio_only")
        if legacy_audio is None:
            legacy_audio = config.get("music_mode")
    if legacy_audio is True:
        return "music"
    if url and is_youtube_music_url(url):
        return "music"
    return "music"


def resolve_media_intent(origin, media_type, *, playlist_entry=None):
    if isinstance(playlist_entry, dict):
        value = playlist_entry.get("media_intent")
        if value in {"track", "album", "playlist", "episode", "movie"}:
            return value
    if origin == "playlist":
        return "playlist"
    if is_music_media_type(media_type):
        return "track"
    return "episode"


def build_output_template(config, *, playlist_entry=None, destination=None, base_dir=None):
    base_dir = base_dir or "."
    config = config or {}
    entry = playlist_entry if isinstance(playlist_entry, dict) else {}
    output_dir = destination or entry.get("folder") or entry.get("directory")
    if not output_dir:
        output_dir = config.get("music_download_folder") or config.get("single_download_folder") or base_dir
    output_dir = resolve_dir(output_dir, base_dir)

    final_format = entry.get("final_format") or config.get("final_format")

    filename_template = entry.get("filename_template") or config.get("filename_template")
    audio_template = entry.get("audio_filename_template") or config.get("audio_filename_template")
    if not audio_template:
        audio_template = config.get("music_filename_template")

    return {
        "output_dir": output_dir,
        "final_format": final_format,
        "filename_template": filename_template,
        "audio_filename_template": audio_template,
        "remove_after_download": bool(entry.get("remove_after_download")),
        "playlist_item_id": entry.get("playlistItemId") or entry.get("playlist_item_id"),
        "source_account": entry.get("account"),
    }


def resolve_source(url):
    if not url:
        return "unknown"
    parsed = urllib.parse.urlparse(url)
    host = (parsed.netloc or "").lower()
    if "music.youtube.com" in host:
        return "youtube_music"
    if "youtube.com" in host or "youtu.be" in host:
        return "youtube"
    return "unknown"


def is_youtube_music_url(url):
    parsed = urllib.parse.urlparse(url)
    return "music.youtube.com" in (parsed.netloc or "").lower()


def build_ytdlp_opts(context):
    operation = context.get("operation") or "download"
    audio_mode = bool(context.get("audio_mode"))
    target_format = context.get("final_format")
    output_template = context.get("output_template")
    overrides = context.get("overrides") or {}

    opts = {
        "quiet": True,
        "no_warnings": True,
        "noplaylist": True,
        "outtmpl": output_template,
        "retries": 3,
        "fragment_retries": 3,
        "overwrites": True,
    }

    cookie_file = context.get("cookie_file")
    if cookie_file:
        opts["cookiefile"] = cookie_file

    if operation == "playlist":
        opts["skip_download"] = True
        opts["extract_flat"] = True
    elif operation == "metadata":
        opts["skip_download"] = True
    else:
        opts["format"] = _FORMAT_AUDIO if audio_mode else _FORMAT_VIDEO
        if audio_mode:
            opts["postprocessors"] = _build_audio_postprocessors(target_format)
            opts["addmetadata"] = True
            opts["embedthumbnail"] = True
            opts["writethumbnail"] = True

    opts = _merge_overrides(opts, overrides, operation=operation)

    if operation == "download":
        for key in _YTDLP_DOWNLOAD_UNSAFE_KEYS:
            opts.pop(key, None)

    return opts


def _build_audio_postprocessors(target_format):
    preferred = (target_format or "mp3").lower()
    if preferred not in _AUDIO_FORMATS:
        logging.warning("Unsupported audio format %s; defaulting to mp3", preferred)
        preferred = "mp3"
    return [
        {
            "key": "FFmpegExtractAudio",
            "preferredcodec": preferred,
            "preferredquality": "0",
        }
    ]


def _merge_overrides(opts, overrides, *, operation):
    if not isinstance(overrides, dict):
        return opts
    unsafe = [key for key in overrides if key in _YTDLP_DOWNLOAD_UNSAFE_KEYS]
    if unsafe and operation == "download":
        logging.warning("Dropping unsafe yt_dlp_opts for download: %s", unsafe)
    for key, value in overrides.items():
        if operation == "download" and key in _YTDLP_DOWNLOAD_UNSAFE_KEYS:
            continue
        if operation == "download" and key not in _YTDLP_DOWNLOAD_ALLOWLIST:
            continue
        opts[key] = value
    return opts


def download_with_ytdlp(
    url,
    temp_dir,
    config,
    *,
    audio_mode,
    final_format,
    cookie_file=None,
    stop_event=None,
):
    if stop_event and stop_event.is_set():
        return None, None
    output_template = os.path.join(temp_dir, "%(title).200s-%(id)s.%(ext)s")
    context = {
        "operation": "download",
        "audio_mode": audio_mode,
        "final_format": final_format,
        "output_template": output_template,
        "cookie_file": cookie_file,
        "overrides": (config or {}).get("yt_dlp_opts") or {},
    }
    opts = build_ytdlp_opts(context)

    info = None
    try:
        with YoutubeDL(opts) as ydl:
            info = ydl.extract_info(url, download=True)
    except Exception as exc:
        raise RuntimeError(f"yt_dlp_download_failed: {exc}")

    if stop_event and stop_event.is_set():
        return None, None

    local_path = None
    if isinstance(info, dict):
        local_path = info.get("_filename")
        if not local_path and info.get("requested_downloads"):
            for req in info.get("requested_downloads"):
                local_path = req.get("filepath") or req.get("filename")
                if local_path:
                    break
    if local_path and os.path.exists(local_path):
        return info, local_path

    for entry in os.listdir(temp_dir):
        if entry.endswith(".part"):
            continue
        candidate = os.path.join(temp_dir, entry)
        if os.path.isfile(candidate):
            return info, candidate

    raise RuntimeError("yt_dlp_no_output")


def extract_meta(info, *, fallback_url=None):
    if not isinstance(info, dict):
        return {}
    return {
        "video_id": info.get("id"),
        "title": info.get("title"),
        "channel": info.get("channel") or info.get("uploader"),
        "artist": info.get("artist") or info.get("uploader"),
        "album": info.get("album"),
        "album_artist": info.get("album_artist"),
        "track": info.get("track") or info.get("title"),
        "track_number": info.get("track_number"),
        "disc": info.get("disc_number"),
        "release_date": info.get("release_date"),
        "upload_date": info.get("upload_date"),
        "description": info.get("description") or "",
        "tags": info.get("tags") or [],
        "url": info.get("webpage_url") or fallback_url,
        "thumbnail_url": info.get("thumbnail"),
    }


def sanitize_for_filesystem(name, maxlen=180):
    if not name:
        return ""
    safe = re.sub(r"[\\/\\?%*:|\"<>]", "_", str(name)).strip()
    safe = re.sub(r"\s+", " ", safe)
    return safe[:maxlen].strip()


def pretty_filename(title, channel, upload_date):
    safe_title = sanitize_for_filesystem(title or "")
    safe_channel = sanitize_for_filesystem(channel or "")
    date = upload_date or ""
    if safe_channel and date:
        return f"{safe_title} - {safe_channel} - {date}".strip(" -")
    if safe_channel:
        return f"{safe_title} - {safe_channel}".strip(" -")
    if date:
        return f"{safe_title} - {date}".strip(" -")
    return safe_title or "media"


def _clean_audio_title(value):
    if not value:
        return ""
    cleaned = _AUDIO_TITLE_CLEAN_RE.sub(" ", value)
    cleaned = _AUDIO_TITLE_TRAIL_RE.sub("", cleaned)
    return re.sub(r"\s+", " ", cleaned).strip()


def _clean_audio_artist(value):
    if not value:
        return ""
    cleaned = _AUDIO_ARTIST_VEVO_RE.sub("", value).strip()
    return re.sub(r"\s+", " ", cleaned).strip()


def normalize_track_number(value):
    if value is None:
        return None
    if isinstance(value, int):
        return value
    value = str(value).strip()
    if not value:
        return None
    if value.isdigit():
        return int(value)
    match = re.match(r"(\d+)", value)
    if match:
        return int(match.group(1))
    return None


def format_track_number(value):
    normalized = normalize_track_number(value)
    if normalized is None:
        return ""
    return f"{normalized:02d}"


def build_audio_filename(meta, ext, *, template=None, fallback_id=None):
    artist = sanitize_for_filesystem(_clean_audio_artist(meta.get("artist") or ""))
    album = sanitize_for_filesystem(_clean_audio_title(meta.get("album") or ""))
    track = sanitize_for_filesystem(_clean_audio_title(meta.get("track") or meta.get("title") or ""))
    track_number = format_track_number(meta.get("track_number"))
    fallback = (fallback_id or "media")[:8]

    fmt = {
        "artist": artist,
        "album": album,
        "track": track,
        "track_number": track_number,
        "ext": ext,
        "id": fallback,
    }

    if template:
        try:
            rendered = template % fmt
            rendered = rendered.strip("/\t ")
            if rendered:
                return rendered
        except Exception:
            pass

    if artist and album:
        if track_number:
            return f"{artist}/{album}/{track_number} - {track}.{ext}"
        return f"{artist}/{album}/{track}.{ext}"
    if artist:
        if track_number:
            return f"{artist}/{track_number} - {track}.{ext}"
        return f"{artist}/{track}.{ext}"
    return f"{track or fallback}.{ext}"


def build_output_filename(meta, fallback_id, ext, template, audio_mode):
    if audio_mode:
        return build_audio_filename(meta, ext, template=template, fallback_id=fallback_id)
    if template:
        try:
            rendered = template % {
                "title": sanitize_for_filesystem(meta.get("title") or fallback_id),
                "uploader": sanitize_for_filesystem(meta.get("channel") or ""),
                "upload_date": meta.get("upload_date") or "",
                "ext": ext,
                "id": fallback_id,
            }
            if rendered:
                return rendered
        except Exception:
            pass
    return f"{pretty_filename(meta.get('title'), meta.get('channel'), meta.get('upload_date'))}_{fallback_id[:8]}.{ext}"


def atomic_move(src, dst):
    try:
        os.replace(src, dst)
    except OSError:
        shutil.copy2(src, dst)
        os.remove(src)


def embed_metadata(local_file, meta, video_id, thumbs_dir):
    if not meta:
        return

    title = meta.get("title") or video_id
    channel = meta.get("channel") or ""
    artist = meta.get("artist") or channel
    album = meta.get("album")
    album_artist = meta.get("album_artist")
    track = meta.get("track")
    track_number = meta.get("track_number")
    disc = meta.get("disc")
    release_date = meta.get("release_date")
    upload_date = meta.get("upload_date") or ""
    description = meta.get("description") or ""
    tags = meta.get("tags") or []
    url = meta.get("url") or f"https://www.youtube.com/watch?v={video_id}"
    thumb_url = meta.get("thumbnail_url")

    date_tag = ""
    raw_date = release_date or upload_date
    if raw_date and len(str(raw_date)) == 8 and str(raw_date).isdigit():
        raw_date = str(raw_date)
        date_tag = f"{raw_date[0:4]}-{raw_date[4:6]}-{raw_date[6:8]}"

    keywords = ", ".join(tags) if tags else ""
    comment = f"YouTubeID={video_id} URL={url}"

    thumb_path = None
    if thumb_url and thumbs_dir:
        try:
            os.makedirs(thumbs_dir, exist_ok=True)
            thumb_path = os.path.join(thumbs_dir, f"{video_id}.jpg")
            resp = requests.get(thumb_url, timeout=15)
            if resp.ok and resp.content:
                with open(thumb_path, "wb") as handle:
                    handle.write(resp.content)
            else:
                thumb_path = None
        except Exception:
            logging.exception("Thumbnail download failed for %s", video_id)
            thumb_path = None

    base_ext = os.path.splitext(local_file)[1] or ".webm"
    ext_lower = base_ext.lower()
    audio_only = ext_lower in [".mp3", ".m4a", ".opus", ".aac", ".flac"]
    tmp_fd, tmp_path = tempfile.mkstemp(suffix=f".tagged{base_ext}", dir=os.path.dirname(local_file))
    os.close(tmp_fd)

    try:
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            local_file,
        ]

        if thumb_path and os.path.exists(thumb_path) and not audio_only:
            cmd.extend([
                "-attach",
                thumb_path,
                "-metadata:s:t",
                "mimetype=image/jpeg",
                "-metadata:s:t",
                "filename=cover.jpg",
            ])

        if title:
            cmd.extend(["-metadata", f"title={title}"])
        if artist:
            cmd.extend(["-metadata", f"artist={artist}"])
        if album:
            cmd.extend(["-metadata", f"album={album}"])
        if album_artist:
            cmd.extend(["-metadata", f"album_artist={album_artist}"])
        if track:
            cmd.extend(["-metadata", f"track={track}"])
        if track_number is not None:
            cmd.extend(["-metadata", f"track={track_number}"])
        if disc is not None:
            cmd.extend(["-metadata", f"disc={disc}"])
        if date_tag:
            cmd.extend(["-metadata", f"date={date_tag}"])
        if description:
            cmd.extend(["-metadata", f"description={description}"])
        if keywords:
            cmd.extend(["-metadata", f"keywords={keywords}"])
        if comment:
            cmd.extend(["-metadata", f"comment={comment}"])

        cmd.extend([
            "-c",
            "copy",
            tmp_path,
        ])

        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        os.replace(tmp_path, local_file)
        logging.info("[%s] Metadata embedded successfully", video_id)
    except subprocess.CalledProcessError:
        logging.exception("ffmpeg metadata embedding failed for %s", video_id)
        try:
            os.unlink(tmp_path)
        except Exception:
            pass
    except Exception:
        logging.exception("Unexpected error during metadata embedding for %s", video_id)
        try:
            os.unlink(tmp_path)
        except Exception:
            pass
    finally:
        if thumb_path:
            try:
                os.unlink(thumb_path)
            except Exception:
                pass


def enqueue_media_metadata(file_path, meta, config):
    try:
        enqueue_metadata(file_path, meta, config)
    except Exception:
        logging.exception("Metadata enqueue failed for %s", file_path)


def record_download_history(db_path, job, filepath, *, meta=None):
    if not filepath:
        return
    video_id = None
    if meta:
        video_id = meta.get("video_id")
    if not video_id:
        video_id = extract_video_id(job.url) or job.id
    playlist_id = job.origin_id if job.origin == "playlist" else None
    conn = sqlite3.connect(db_path, check_same_thread=False)
    try:
        cur = conn.cursor()
        cur.execute(
            "INSERT OR REPLACE INTO downloads (video_id, playlist_id, downloaded_at, filepath) VALUES (?, ?, ?, ?)",
            (video_id, playlist_id, utc_now(), filepath),
        )
        conn.commit()
    finally:
        conn.close()


def extract_video_id(url):
    if not url:
        return None
    if "youtube.com" in url:
        match = re.search(r"v=([a-zA-Z0-9_-]{6,})", url)
        if match:
            return match.group(1)
    if "youtu.be" in url:
        parsed = urllib.parse.urlparse(url)
        if parsed.path:
            return parsed.path.lstrip("/").split("/")[0]
    return None


def is_retryable_error(error):
    if isinstance(error, (DownloadError, ExtractorError)):
        message = str(error).lower()
    else:
        message = str(error).lower()
    if "drm" in message:
        return False
    if "http error 403" in message or "http error 404" in message:
        return False
    if "403" in message and "http" in message:
        return False
    if "404" in message and "http" in message:
        return False
    if "not available" in message or "private" in message:
        return False
    if "unavailable" in message and "region" in message:
        return False
    if "extractor" in message or "unable to extract" in message:
        return True
    if "timed out" in message or "timeout" in message:
        return True
    if "temporary failure" in message or "connection reset" in message:
        return True
    return True
